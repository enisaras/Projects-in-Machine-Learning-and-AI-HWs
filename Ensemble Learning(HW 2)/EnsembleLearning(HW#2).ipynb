{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "successful-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages needed \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from numpy import log, dot, e\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import entropy\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "thick-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"breast-cancer-wisconsin.data\")\n",
    "\n",
    "#Link to the dataset: https://archive.ics.uci.edu/ml/datasets/breast+cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ruled-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column names\n",
    "dataset.rename(columns = {'1000025':'id', \n",
    "                       '5':'clump thickness',\n",
    "                        '1': 'cell size',\n",
    "                         '1.1': 'cell shape',\n",
    "                         '1.2': 'Marginal Adhesion',\n",
    "                        '2': 'Single Epithelial Cell Size',\n",
    "                         '1.3': 'Bare Nuclei',\n",
    "                         '3': 'Bland Chromatin',\n",
    "                         '1.4': 'Normal Nucleoli',\n",
    "                         '1.5': 'Mitoses',\n",
    "                         '2.1': 'result'},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "christian-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all \"?\" with the average value in the Bare Nuclei columns mean to make the replaced data as accurate as possible  \n",
    "dataset['Bare Nuclei'].replace({'?': '4'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "above-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 698 entries, 0 to 697\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   id                           698 non-null    int64\n",
      " 1   clump thickness              698 non-null    int64\n",
      " 2   cell size                    698 non-null    int64\n",
      " 3   cell shape                   698 non-null    int64\n",
      " 4   Marginal Adhesion            698 non-null    int64\n",
      " 5   Single Epithelial Cell Size  698 non-null    int64\n",
      " 6   Bare Nuclei                  698 non-null    int64\n",
      " 7   Bland Chromatin              698 non-null    int64\n",
      " 8   Normal Nucleoli              698 non-null    int64\n",
      " 9   Mitoses                      698 non-null    int64\n",
      " 10  result                       698 non-null    int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 60.1 KB\n"
     ]
    }
   ],
   "source": [
    "#change the last object to an integer\n",
    "dataset['Bare Nuclei'] = dataset['Bare Nuclei'].astype('int64')\n",
    "dataset.info()\n",
    "#lastly, map the class column as 0 and 1 instead of 2 and 4 so it is binary\n",
    "dataset.result = dataset.result.map({2:0,4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "accepted-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#id and result are clearly unrelated, lets drop that column\n",
    "dataset = dataset.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "warming-farmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clump thickness', 'cell size', 'cell shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']\n"
     ]
    }
   ],
   "source": [
    "X = dataset[columns]\n",
    "y = dataset.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ordered-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training data 70-30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.89, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "chinese-rugby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the GINI criterion and best splitter:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       412\n",
      "           1       0.84      0.96      0.90       210\n",
      "\n",
      "    accuracy                           0.93       622\n",
      "   macro avg       0.91      0.93      0.92       622\n",
      "weighted avg       0.93      0.93      0.93       622\n",
      "\n",
      "-------------------------------------------------------\n",
      "With the entropy criterion and best splitter:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       412\n",
      "           1       0.92      0.93      0.93       210\n",
      "\n",
      "    accuracy                           0.95       622\n",
      "   macro avg       0.94      0.94      0.94       622\n",
      "weighted avg       0.95      0.95      0.95       622\n",
      "\n",
      "-------------------------------------------------------\n",
      "With the gini criterion and random splitter:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       412\n",
      "           1       0.94      0.89      0.91       210\n",
      "\n",
      "    accuracy                           0.94       622\n",
      "   macro avg       0.94      0.93      0.94       622\n",
      "weighted avg       0.94      0.94      0.94       622\n",
      "\n",
      "-------------------------------------------------------\n",
      "With the entropy criterion and random splitter:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       412\n",
      "           1       0.83      0.88      0.85       210\n",
      "\n",
      "    accuracy                           0.90       622\n",
      "   macro avg       0.88      0.89      0.89       622\n",
      "weighted avg       0.90      0.90      0.90       622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Try modifying one or more of the input parameters and describe what changes you notice in your results\n",
    "clf_gini = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, splitter = \"best\")\n",
    "clf_gini = clf.fit(X_train,y_train)\n",
    "y_pred = clf_gini.predict(X_test)\n",
    "print(\"With the GINI criterion and best splitter:\\n\",classification_report(y_test, y_pred))\n",
    "print(\"-\"*55)\n",
    "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, splitter = \"best\")\n",
    "clf_entropy = clf_entropy.fit(X_train,y_train)\n",
    "y_pred = clf_entropy.predict(X_test)\n",
    "print(\"With the entropy criterion and best splitter:\\n\",classification_report(y_test, y_pred))\n",
    "print(\"-\"*55)\n",
    "clf_random_gini = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, splitter = \"random\")\n",
    "clf_random_gini = clf_random_gini.fit(X_train,y_train)\n",
    "y_pred = clf_random_gini.predict(X_test)\n",
    "print(\"With the gini criterion and random splitter:\\n\",classification_report(y_test, y_pred))\n",
    "print(\"-\"*55)\n",
    "clf_entropy_random = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, splitter = \"random\")\n",
    "clf_entropy_random = clf_entropy_random.fit(X_train,y_train)\n",
    "y_pred = clf_entropy_random.predict(X_test)\n",
    "print(\"With the entropy criterion and random splitter:\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-oxide",
   "metadata": {},
   "source": [
    "When changing the paramaters I noticed very few differences in the accuracy of the model, the best performing model was a tie between \"With the GINI criterion and best splitter\" and \"With the gini criterion and random splitter:\" at 96% accuracy. This was surprising since the two paramaters are the polar opposites in the training I have done. \n",
    "The GINI index chooses the amount of probability that when the feature is classified incorrectly and Entropy is the randomness of the dataset. Another performance difference noticed here is with the random splitter, the model seems to be way more precise predicting the 0's than 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "flush-antigua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61956522 0.80978261 0.87318841 0.61956522 0.9365942  0.74637681\n",
      " 0.87318841 1.         0.87222222 0.93611111]\n",
      "Mean 10-Fold : 0.8286594202898552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       415\n",
      "           1       0.96      0.93      0.94       207\n",
      "\n",
      "    accuracy                           0.96       622\n",
      "   macro avg       0.96      0.96      0.96       622\n",
      "weighted avg       0.96      0.96      0.96       622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#bagging classifier using the KNeighborsClassifier algorithm\n",
    "model = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "k_fold_result_bagging = cross_val_score(model, X, y, cv=10,scoring='r2')\n",
    "print(k_fold_result_bagging)\n",
    "print(f\"Mean 10-Fold : {np.mean(k_fold_result_bagging)}\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "subsequent-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55615942 0.74637681 0.87318841 0.61956522 0.87318841 0.68297101\n",
      " 0.80978261 1.         1.         0.87222222]\n",
      "Mean 10-Fold : 0.8033454106280192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       415\n",
      "           1       0.95      0.91      0.93       207\n",
      "\n",
      "    accuracy                           0.95       622\n",
      "   macro avg       0.95      0.94      0.95       622\n",
      "weighted avg       0.95      0.95      0.95       622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #Boost classifier using the DecisionTreeClassifier algorithm\n",
    "adaboost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5, random_state=23), n_estimators=5, learning_rate=0.2, random_state=23)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "k_fold_result_boosting = cross_val_score(adaboost, X, y, cv=10,scoring='r2')\n",
    "print(k_fold_result_boosting)\n",
    "print(f\"Mean 10-Fold : {np.mean(k_fold_result_boosting)}\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-drilling",
   "metadata": {},
   "source": [
    "The k-fold cross validation is a popular machine learning procedure that estimates the skill of a model on data. As we can see from the results outputted, even though both models performed with incredible accuracies on the Wisconsin Breast Cancer dataset the k-fold scores were much lower.\n",
    "The difference between the two mean k-fold results is not significant but some reasons why they are not the same are because they use seperate base algorithms and trivially they are seperate methods of ensemble learning, bagging uses the base learning algorithms and trians them seperately to average out a more accurate and precise result, Ada Boosting on the other hand penalizes wrong guesses and rewards correct ones, the idea is that every base learner in sequence will improve the results compared to the last one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-croatia",
   "metadata": {},
   "source": [
    "Compare the effectiveness of the three models implemented above. Clearly describe the metric you are using for comparison. Describe (with examples) Why is this metric(metrics) suited/appropriate for the problem at hand? How would a choice of a different metric impact your results? Can you demonstrate that?\n",
    "\n",
    "From my experiment with the three ensemble learning models, all three did very well with predicting the benign and malignant tumors, the metric I will be using to compare the effectiveness of the three models is precision.\n",
    "Precision is the ratio between true positives and true positives and false positives together, in this dataset that would be the correctly predicted tumors divided by all the tumors in the dataset. The precision metric helps us understand how well the model did because it tells us how often the model is correct when the tumor is malignant.\n",
    "\n",
    "Comparing the three ensemble learning techniques using the precision metric, they all performed incredibly similary and in a very high percentage, with the least being 91% and as high as 96%, which is a very good precision score for any ensemble learning model. All the models seem to be doing a better job when predicting the benign tumors than the malignant ones, which is an expected outcome since there are more benign cases in the dataset. The only big discrepancy in the results is compared to the precision of 1's in the bagging and boosting methods, the decision tree underperformed by more than 10% in the entropy and random splitter case. \n",
    "\n",
    "I went with precision because on the dataset I have used is one where there are way less malignant tumors than benign ones, meaning being precise in this case will determine how the model truly performed.\n",
    "\n",
    "If I went with accuracy it could be misleading if a model only guessed the malignant tumors correctly and none of the benign ones, it would have a high accuracy number when in reality it is not a very high performing model for this problem. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
